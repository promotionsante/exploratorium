---
title: "Prepare data - subfunctions"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)
library(readxl)
library(here)
library(tools)
library(readr)
library(dplyr)
library(tidygeocoder)
library(sf)
library(glue)
```

```{r development-load}
# Load already included functions if relevant
pkgload::load_all(export_all = FALSE)
```

# Import the raw projects data with `import_raw_data()`

```{r function-import_raw_data}
#' Import the raw data
#' 
#' @param name_raw_file Character. Name of the raw data file.
#' @param pkg_dir Character. Path to the package.
#' 
#' @importFrom readxl read_excel
#' @importFrom tools file_ext
#' @importFrom glue glue
#' 
#' @return A tibble corresponding to raw data
#' 
#' @noRd
import_raw_data <- function(
    name_raw_file = "PGV.xlsx",
    pkg_dir = system.file(package = "observatoire")
) {
  
  raw_data_path <- file.path(
    pkg_dir,
    "data-projects-raw", 
    name_raw_file
  )
  
  if (isFALSE(file.exists(raw_data_path))) {
    stop(glue("There is no file called {name_raw_file} in /data-projects-raw"))
  }
  
  if (isFALSE(file_ext(name_raw_file) == "xlsx")) {
    stop("The raw file must be an xlsx file")
  }
  
  read_excel(
    path = raw_data_path
  )
  
}
```

```{r example-import_raw_data}
# Import the raw data
import_raw_data()
```

```{r tests-import_raw_data}
test_that("Test that the import of the raw data is ok", {
  
  # Create a temp folder with data-projects-raw subfolder and save a toy object inside
  my_temp_dir <- tempfile("test-import-data")
  dir.create(my_temp_dir)
  dir.create(file.path(my_temp_dir, "data-projects-raw"))
  
  writexl::write_xlsx(
    x = iris[1:2, ], 
    path = file.path(my_temp_dir, "data-projects-raw", "iris.xlsx")
  )
  
  write.csv(
    x = iris[1:2, ], 
    file = file.path(my_temp_dir, "data-projects-raw", "iris.csv")
  )
  
  #' @description Testing that there is no error if the xlsx data exists
  expect_error(
    res_iris_import <- import_raw_data(
      name_raw_file = "iris.xlsx",
      pkg_dir = my_temp_dir
    ), regexp = NA
  )
  
  #' @description Testing that the object is the expected one
  expect_equal(
    object = res_iris_import |> 
      dplyr::mutate(
        dplyr::across(
          everything(),
          as.character
        )),
    expected = tibble::as_tibble(iris[1:2, ]) |> 
      dplyr::mutate(
        dplyr::across(
          everything(),
          as.character
        ))
  )
  
  #' @description Testing that there is an error if the data does not exist
  expect_error(
    import_raw_data(
      name_raw_file = "notexists.xlsx",
      pkg_dir = my_temp_dir
    )
  )
  
  #' @description Testing that there is an error if the data is not a xlsx file
  expect_error(
    import_raw_data(
      name_raw_file = "iris.csv",
      pkg_dir = my_temp_dir
    )
  )
  
  unlink(
    my_temp_dir, 
    recursive = TRUE
  )
  
})
```

# Add the proper colums names to the projects data with `add_col_raw_data()`

```{r function-add_col_raw_data}
#' Add the proper colums names to the projects data
#' 
#' @param data Tibble. Raw data about projects.
#' @param dic_variables Tibble. Variables dictionaries. Mainly used for examples and unit testing purpose.
#' 
#' @importFrom readr read_csv2
#' 
#' @return The raw data about the projects with the good columns names.
#'
#' @noRd
add_col_raw_data <- function(
    data,
    dic_variables = NULL
){
  
  # Import the variables dictionary saved in the package
  if (is.null(dic_variables)) {
    dic_variables <- read_csv2(
      system.file(
        "data-dic", 
        "dic_variables.csv", 
        package = "observatoire"
      ),
      show_col_types = FALSE
    )
  }
  
  # Check if all columns are present
  all_expected_columns_are_present <- all(sort(colnames(data)) == sort(dic_variables$de))
  if (isFALSE(all_expected_columns_are_present)) {
    stop(
      paste(
        "The columns in the raw projects data file are not the expected ones.",
        "Please, make sure that the columns are those described in the file dic_variables.csv.",
        sep = "\n"
      )
    )
  }
  
  # Replace german column names with the names of the variables
  colnames(data) <- dic_variables$name_variable[
    match(
      dic_variables$de, 
      names(data)
    )
  ]
  
  return(data)
  
}
```

```{r example-add_col_raw_data}
# Load the toy datasets
data("toy_data_pgv")
data("toy_dic_variables")

# Add the good columns names
toy_data_pgv |> 
  add_col_raw_data(
    dic_variables = toy_dic_variables
  )
```

```{r tests-add_col_raw_data}
test_that("Test that the addition of the variables names is ok", {
  
  # Load the raw data
  data("toy_data_pgv")
  
  # Load the variables dictionary
  data("toy_dic_variables")

  # Add colnames
  raw_data_with_colnames <- add_col_raw_data(
    data = toy_data_pgv,
    dic_variables = toy_dic_variables
  )
  
  #' @description Testing that the colnames are the expected ones
  expect_equal(
    object = sort(colnames(raw_data_with_colnames)), 
    expect = sort(toy_dic_variables$name_variable)
  )
  
  colnames(raw_data_with_colnames) <- colnames(toy_data_pgv)
  
  #' @description Testing that the data is not modified
  expect_equal(
    object = raw_data_with_colnames, 
    expect = toy_data_pgv
  )
  
  colnames(toy_data_pgv)[1] <- "mistake"
  #' @description Testing that there is an error if columns are not the expected ones
  expect_error(
    add_col_raw_data(
      data = toy_data_pgv
    )
  )
  
})
```

# Clean the raw projects data with `clean_raw_data()`

```{r function-clean_raw_data}
#' Clean the raw projects data
#' 
#' @param data Tibble. Raw data about projects, with the good columns names.
#' 
#' @importFrom dplyr mutate across
#' @importFrom tidyselect contains
#' 
#' @return A tibble with clean data.
#' 
#' @noRd
clean_raw_data <- function(
    data
){
  
  # Remove the first row containing some French column names
  if (data[1, 1] == "Titre") {
    data <- data[-1, ] 
  }
  
  # Convert to digital format
  ## Standardize thousand separators in budget columns
  data_standardized_thousand_sep <- data |> 
    mutate(
      across(
        contains("budget"),
        ~ gsub("^CHF\\s+|\\'", "", .x)
      )
    )
  
  ## Convert to digital format
  clean_data <- data_standardized_thousand_sep |>
    mutate(
      across(
        contains("budget"),
        as.numeric
      )
    )
  
  return(clean_data)
  
}
```

```{r example-clean_raw_data}
# Load the toy datasets
data("toy_data_pgv")
data("toy_dic_variables")

toy_data <- toy_data_pgv |> 
  add_col_raw_data(
    dic_variables = toy_dic_variables
  )

# Clean the data
toy_data |> 
  clean_raw_data()
```

```{r tests-clean_raw_data}
test_that("Test that the cleaning of the raw data is ok", {
  
  data("toy_data_pgv")

  clean_data <- toy_data_pgv |>
    add_col_raw_data() |>
    clean_raw_data()
  
  #' @description Testing that there is not more issue with French word in the first line
  expect_false(
    object = (clean_data[1, 1] == "Titre")
  )
  
  #' @description Testing that there is not more issue with the thousand sep
  expect_equal(
    object = clean_data |>
      dplyr::filter(
        dplyr::if_any(
          tidyselect::starts_with("budget"),
          ~ grepl("^CHF|\\'", .x))) |>
      nrow(), 
    expected = 0
  )
  
})
```

# Get the coordinates of the principale organization with `get_coord_main_resp_orga()`

```{r function-get_coord_main_resp_orga}
#' Get the coordinates of the principale organization
#' 
#' @param data Tibble. Raw data about projects, with the good columns names.
#' @param cantons_sf Sf data. Cantons geometry. Mainly used for examples and unit testing purpose.
#'
#' @importFrom tidygeocoder geocode
#' @importFrom dplyr mutate select filter
#' @importFrom glue glue
#' @importFrom sf st_read st_contains st_point st_union st_as_sf
#' @importFrom purrr map_lgl
#' 
#' @return A tibble with a column with the coordinates of the principale organization.
#' 
#' @noRd
get_coord_main_resp_orga <- function(
    data,
    cantons_sf = NULL
){
  
  # Check if some cities are missing
  nb_missing_cities <- data |> 
    filter(is.na(city_code_main_resp_orga)) |> 
    nrow()
  
  if (nb_missing_cities > 0) {
    message(
      glue(
        "{nb_missing_cities} project.s is.are not associated to a city.",
        "Please correct the problem before restarting the data preparation workflow,",
        "or this.these project.s will not be displayed on the observatory map.",
        .sep = "\n"
      )
    )
  }
  
  # Get the GPS coordinates
  data_with_long_lat <- data |> 
    mutate(
      country = "Switzerland"
    ) |> 
    geocode(
      city = city_code_main_resp_orga, 
      country = country,
      method = "osm", 
      lat = latitude , 
      long = longitude
    ) |> 
    select(- country)
  
  # Create sf points
  data_with_coord <- data_with_long_lat |>
    st_as_sf(
      coords = c("longitude", "latitude"),
      crs = 4326, 
      remove = FALSE,
      na.fail = FALSE
    )
  
  # Check if the points are in Switzerland
  if (is.null(cantons_sf)) {
    cantons_sf <- read_cantons_sf()
  }
  
  switzerland_sf <- st_union(
    x = cantons_sf
  )
  
  check_is_in_switzerland <- data_with_coord |> 
    filter(!is.na(longitude) & !is.na(latitude)) |> 
    st_contains(
      x = switzerland_sf,
      y = _,
      sparse = FALSE
    ) |> 
    as.logical()
  
  
  if (any(isFALSE(check_is_in_switzerland))) {
    stop(
      paste(
        "There is an issue in the geocoding of the principale organisation.",
        "Some points that have been found are not in Switzerland.",
        sep = "\n"
      )
    )
  }
  
  return(data_with_coord)
  
}
```

```{r example-get_coord_main_resp_orga}
# Load the toy datasets
data("toy_data_pgv")
data("toy_dic_variables")
data("toy_cantons_sf")

toy_data <- toy_data_pgv |> 
  add_col_raw_data(
    dic_variables = toy_dic_variables
  ) |> 
  clean_raw_data()

# Geocode the principale organisation of the project
toy_data |> 
  get_coord_main_resp_orga(
    cantons_sf = toy_cantons_sf
  )
```

```{r tests-get_coord_main_resp_orga}
test_that("Test that the geocoding of the data is ok", {
  
  toy_data <-
    structure(
      list(
        city_code_main_resp_orga = c(
          "Zürich",
          "Sion",
          "St. Gallen",
          NA,
          "Le Cerneux-Veusil",
          "Genève",
          "Münsingen"
        )
      ),
      row.names = c(NA,
                    -7L),
      class = c("tbl_df", "tbl", "data.frame")
    )

  #' @description Testing that there is a message if there is an issue
  expect_message(
    res_geocode <- get_coord_main_resp_orga(
      data = toy_data,
      cantons_sf = toy_cantons_sf
    ),
    regexp = "1 project.s is.are not associated to a city."
  )
  
  #' @description Testing that there is no error is an usual situation
  expect_error(
    res_geocode <- get_coord_main_resp_orga(
      data = toy_data,
      cantons_sf = toy_cantons_sf
    ),
    regexp = NA
  )
  
})
```

# Get the canton of the principale organization with `get_canton_main_resp_orga()`

```{r function-get_canton_main_resp_orga}
#' Get the canton of the principale organization
#' 
#' @param data Tibble. Raw data about projects, with the good columns names.
#' @param cantons_sf Sf data. Cantons geometry. Mainly used for examples and unit testing purpose.
#' 
#' @importFrom dplyr filter mutate select left_join rename
#' @importFrom glue glue
#' @importFrom sf st_read st_intersects st_as_sf st_join
#' @importFrom purrr map_df 
#' @importFrom tibble as_tibble tibble
#' 
#' 
#' @return A tibble with the name of the canton
#' 
#' @noRd
get_canton_main_resp_orga <- function(
    data, 
    cantons_sf = NULL
){
  
  # Check if some GPS points are missing
  nb_missing_gps_points <- data |> 
    filter(is.na(longitude) | is.na(latitude)) |> 
    nrow()
  
  if (nb_missing_gps_points > 0) {
    message(
      glue(
        "{nb_missing_gps_points} project.s is.are not associated to a GPS point.",
        "Please correct the problem before restarting the data preparation workflow,",
        "or this.these project.s will not be displayed on the observatory map.",
        .sep = "\n"
      )
    )
  }
  
  # Detect the id of the cantons
  if (is.null(cantons_sf)) {
    cantons_sf <- read_cantons_sf()
  }
  
  data_with_coord <- data |>
    select(short_title, geometry)
  
  data_with_id_canton <- st_join(
    x = data_with_coord, 
    y = select(cantons_sf, HASC_1)
  ) |> 
    rename(
      id_canton = HASC_1
    )
  
  # Add the canton to the raw data
  data_with_canton <- st_join(
    x = data, 
    y = data_with_id_canton,
    suffix = c("", "extra")
  ) |> 
    select(-short_titleextra)
  
  # Check if all cantons have been found
  nb_canton_not_found <- data_with_canton |> 
    filter(!is.na(longitude) & !is.na(latitude)) |> 
    filter(is.na(id_canton)) |> 
    nrow()
  
  if (nb_canton_not_found > 0) {
    stop(
      glue(
        "{nb_canton_not_found} project.s is.are not associated to a canton.",
        "Please correct the problem before restarting the data preparation workflow,",
        "or this.these project.s will not be displayed on the observatory map.",
        .sep = "\n"
      )
    )
  }
  
  return(data_with_canton)
  
}
```

```{r example-get_canton_main_resp_orga}
# Load the toy datasets
data("toy_data_pgv")
data("toy_dic_variables")
data("toy_cantons_sf")

toy_data <- toy_data_pgv |> 
  add_col_raw_data(
    dic_variables = toy_dic_variables
  ) |> 
  clean_raw_data() |> 
  get_coord_main_resp_orga(
    cantons_sf = toy_cantons_sf
  )

# Geocode the principale organisation of the project
toy_data |> 
  get_canton_main_resp_orga(
    cantons_sf = toy_cantons_sf
  )
```

```{r tests-get_canton_main_resp_orga}
test_that("Test that the detection of the canton is ok", {
  
  toy_data <-
    structure(
      list(
        short_title = c(
          "1+1=3  PGV03.038",
          "Action Diabète PGV01.057",
          "Angehörigen-Expert/innen PGV03.078",
          "DZ SUCHT",
          "EMIA"
        ),
        longitude = c(8.5410422,
                      7.3588795, 7.4521749, NA, 6.957368),
        latitude = c(47.3744489,
                     46.2311749, 46.9484742, NA, 47.184604),
        geometry = structure(
          list(
            structure(c(8.5410422, 47.3744489), class = c("XY", "POINT",
                                                          "sfg")),
            structure(c(7.3588795, 46.2311749), class = c("XY",
                                                          "POINT", "sfg")),
            structure(c(7.4521749, 46.9484742), class = c("XY",
                                                          "POINT", "sfg")),
            structure(c(NA_real_, NA_real_), class = c("XY",
                                                       "POINT", "sfg")),
            structure(c(6.957368, 47.184604), class = c("XY",
                                                        "POINT", "sfg"))
          ),
          class = c("sfc_POINT", "sfc"),
          precision = 0,
          bbox = structure(
            c(
              xmin = 6.957368,
              ymin = 46.2311749,
              xmax = 8.5410422,
              ymax = 47.3744489
            ),
            class = "bbox"
          ),
          crs = structure(
            list(input = "EPSG:4326", wkt = "GEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]"),
            class = "crs"
          ),
          n_empty = 1L
        )
      ),
      row.names = c(NA,
                    -5L),
      sf_column = "geometry",
      agr = structure(
        c(
          short_title = NA_integer_,
          longitude = NA_integer_,
          latitude = NA_integer_
        ),
        class = "factor",
        levels = c("constant",
                   "aggregate", "identity")
      ),
      class = c("sf", "tbl_df", "tbl", "data.frame")
    )
  
  # Load the toy cantons geometry
  data("toy_cantons_sf")
  
  #' @description Testing that there is a message if there is an issue
  expect_message(
    get_canton_main_resp_orga(
      data = toy_data, 
      cantons_sf = toy_cantons_sf
    ), 
    regexp = "1 project.s is.are not associated to a GPS point"
  )
  
  #' @description Testing that there is no error in an usual case
  expect_error(
    res_toy_data <- get_canton_main_resp_orga(
      data = toy_data, 
      cantons_sf = toy_cantons_sf
    ), 
    regexp = NA
  )
  
  #' @description Testing that the feature provide the expected output
  expect_equal(
    object = res_toy_data$id_canton,
    expected = c(
      "CH.ZH", 
      "CH.VS", 
      "CH.BE", 
      NA, 
      "CH.BE"
    )
  )
  
})
```

# Get the number of cantons influenced with `get_nb_cantons_influenced()`

```{r function-get_nb_cantons_influenced}
#' Get the number of cantons influenced
#' 
#' @param data Tibble. Raw data about projects, with the good columns names.
#' 
#' @importFrom dplyr mutate
#' 
#' @return A tibble with a column with the number of cantons influenced
#' 
#' @noRd
get_nb_cantons_influenced <- function(
    data
    ){
  
  data |> 
    mutate(
      nb_cantons_influenced = lengths(gregexpr(
          ",", 
          geo_range
        )
    ) + 1) 
  
}
```
  
```{r example-get_nb_cantons_influenced}
# Load the toy datasets
data("toy_data_pgv")
data("toy_dic_variables")

raw_data <- toy_data_pgv |> 
  add_col_raw_data(
    dic_variables = toy_dic_variables
  ) |> 
  clean_raw_data()

# Get the number of cantons influenced
raw_data |> 
  get_nb_cantons_influenced() |> 
  select(geo_range, nb_cantons_influenced)
```
  
```{r tests-get_nb_cantons_influenced}
test_that("Test that the computation of the nb of cantons is ok", {
  
  toy_data <-
    structure(
      list(
        geo_range = c(
          "Aargau,\r\nSt. Gallen",
          "Wallis",
          "Appenzell Ausserrhoden,\r\nAppenzell Innerrhoden,\r\nBasel-Landschaft,\r\nBasel-Stadt,\r\nBern,\r\nGenf,\r\nLuzern,\r\nNidwalden,\r\nObwalden,\r\nSt. Gallen,\r\nThurgau,\r\nWaadt,\r\nZürich",
          "Zürich"
        )
      ),
      row.names = c(NA, -4L),
      class = c("tbl_df", "tbl",
                "data.frame")
    )
  
  res_nb_cantons_influenced <- toy_data |> 
    get_nb_cantons_influenced()
  
  #' @description Testing that the feature provide the expected output
  expect_equal(
    object = res_nb_cantons_influenced$nb_cantons_influenced,
    expected = c(2, 2, 13, 2)
  )
  
})
```
  
# Get the proportion of the budget for GFCH, principale organization and third party with `get_prop_budget()`

```{r function-get_prop_budget}
#' Get the proportion of the budget for GFCH, principale organization and third party
#' 
#' @param data Tibble. Raw data about projects, with the good columns names.
#' 
#' @importFrom dplyr mutate across
#' @importFrom tidyselect starts_with
#' 
#' @return A tibble with 3 columns about the proportion of the budget paid by each actor
#' 
#' @noRd
get_prop_budget <- function(
    data
    ){
  
  data |> 
    mutate(
      across(
        starts_with("budget_"), 
        ~ .x / total_budget, 
        .names = "prop_{.col}"
      )
    )
  
}
```
  
```{r example-get_prop_budget}
# Load the toy datasets
data("toy_data_pgv")
data("toy_dic_variables")

# Import the raw data and perform the first preparations
raw_data <- toy_data_pgv |> 
  add_col_raw_data(
    dic_variables = toy_dic_variables
  ) |> 
  clean_raw_data()

# Get the proportion of the budget for GFCH, principale organization and third party
raw_data |> 
  get_prop_budget()
```
  
```{r tests-get_prop_budget}
test_that("Test that the computation of the prop of the budget is ok", {
  
  toy_data <-
    structure(
      list(
        budget_gfch = c(2e+05, 2e+06, 1500000, 182635),
        budget_orga = c(25000, 1714500, 160346, 45000),
        budget_third_party = c(361720,
                               380000, 1500000, 20000),
        total_budget = c(586720, 4094500,
                         3160346, 247635)
      ),
      row.names = c(NA, -4L),
      class = c("tbl_df",
                "tbl", "data.frame")
    )
  
  res_prop_budget <- toy_data |> 
    get_prop_budget() |> 
    dplyr::mutate(
      sum_prop_budget = 
        prop_budget_gfch + 
        prop_budget_third_party + 
        prop_budget_orga
    )
  
  #' @description Testing that the sum of all the proportion equals 1
  expect_true(
    object = all(res_prop_budget$sum_prop_budget == 1)
  )
  
})
```
  
# Translate the data (values in the table) in FR and DE with `translate_values_in_data()`

```{r function-translate_values_in_data}
#' Translate the data (values in the table) in FR and DE
#' 
#' @param data Tibble. Raw data about projects, with the good columns names.
#' 
#' @return A list of 2 tibbles (FR and DE)
#' 
#' @noRd
translate_values_in_data <- function(
    data
    ){
  
  #TODO
  list(
    data_fr = data, 
    data_de = data
  )
    
}
```
  
```{r example-translate_values_in_data}
# Import the raw data and perform the first preparations
raw_data <- import_raw_data() |> 
  add_col_raw_data() |> 
  clean_raw_data()

# Get the translated data in FR and DE
raw_data |> 
  translate_values_in_data()
```
  
```{r tests-translate_values_in_data}
test_that("Test that the translation of the data is ok", {
  #TODO
})
```

# Save the prepared data (FR and DE versions) with `save_projects_data()`

```{r function-save_projects_data}
#' Save the prepared data (FR and DE versions) as .rds objects in the package
#' 
#' @param list_data_fr_de List. With 2 tibbles corresponding to data in FR and data in DE.
#' @param pkg_dir Character. Path to the package.
#' 
#' @importFrom purrr walk
#' 
#' @return Nothing, used for side effect. Save 2 rds files in the package.
#' 
#' @noRd
save_projects_data <- function(
    list_data_fr_de, 
    pkg_dir = system.file(package = "observatoire")
    ){
  
  # Check that the list contains 2 tibbles (FR and DE)
  data_fr_and_de_in_names <- all(
    c("data_fr", "data_de") %in% names(list_data_fr_de)
  )
  
  if (isFALSE(data_fr_and_de_in_names)) {
    stop(
      paste(
        "The object to be saved does not contain FR and DE data",
        "Please check the origin of this issue",
        sep = "\n"
      )
    )
  }
  
  # Save FR data
  saveRDS(
    object = list_data_fr_de$data_fr, 
    file = file.path(
      pkg_dir, 
      "data-projects",
      "projects_fr.rds"
    )
  )
  
  # Save DE data
  saveRDS(
    object = list_data_fr_de$data_de, 
    file = file.path(
      pkg_dir, 
      "data-projects",
      "projects_de.rds"
    )
  )
  
  # Print a message about the time of modification
  available_files_in_data <- list.files(
    file.path(
      pkg_dir, 
      "data-projects"
    )
  )
  
  c("projects_fr.rds", "projects_de.rds") |> 
    walk(
      function(.x){
        if (isTRUE(.x %in% available_files_in_data)) {
          message(
            glue(
              "{.x} has been updated at {file.info(file.path(pkg_dir, 'data-projects', .x))$mtime}"
              )
            )
          } else {
            message(
              glue(
                "{.x} does not exist in the inst/data folder"
              )
            )
          }
        }
      )
    
}
```
  
```{r example-save_projects_data}
# Load the toy datasets
data("toy_data_pgv")
data("toy_dic_variables")

# Perform the some preparations
list_translated_data <- toy_data_pgv |> 
  add_col_raw_data(
    dic_variables = toy_dic_variables
  ) |> 
  clean_raw_data() |> 
  translate_values_in_data()

# Create a temp folder with data-projects subfolder
my_temp_dir <- tempfile("test-export-data")
dir.create(my_temp_dir)
dir.create(file.path(my_temp_dir, "data-projects"))

# Save rds data in FR and DE
list_translated_data |> 
  save_projects_data(
    pkg_dir = my_temp_dir
  )

# Delete the temp folder
unlink(
  my_temp_dir, 
  recursive = TRUE
)
```
  
```{r tests-save_projects_data}
test_that("Test that the saving of the data in inst works", {
  
  # Create a temp folder with data subfolder
  my_temp_dir <- tempfile("test-export-data")
  dir.create(my_temp_dir)
  dir.create(file.path(my_temp_dir, "data-projects"))
  
  # Create toy lists
  toy_list_ok <- list(
    data_fr = iris, 
    data_de = iris
  )
  
  toy_list_nok <- list(
    data_frzd = iris, 
    data_defe = iris
  )
  
  #' @description Testing that there is an error of the list does not contain the object data_fr and data_de
  expect_error(
    object = save_projects_data(
      toy_list_nok, 
      pkg_dir = my_temp_dir
    ), 
    regexp = "The object to be saved does not contain FR and DE data"
  )
   
  #' @description Testing that the export is ok
  expect_message(
    object = save_projects_data(
      toy_list_ok, 
      pkg_dir = my_temp_dir
    ), 
    regexp = "has been updated at"
  )
  
  unlink(my_temp_dir, recursive = TRUE)
  
})
```

```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(
  flat_file = "dev/flat_prepare_data_subfunctions.Rmd", 
  vignette_name = NA,
  check = FALSE
)
```

